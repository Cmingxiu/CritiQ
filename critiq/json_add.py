import os
import json

def count_jsonl_lines(folder):
    """ç»Ÿè®¡æŒ‡å®šæ–‡ä»¶å¤¹å†…æ‰€æœ‰ .jsonl æ–‡ä»¶çš„æœ‰æ•ˆè¡Œæ•°"""
    total_lines = 0
    for root, _, files in os.walk(folder):
        for file_name in files:
            if file_name.endswith(".jsonl"):
                file_path = os.path.join(root, file_name)
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        for line_number, line in enumerate(f, start=1):
                            stripped_line = line.strip()
                            if not stripped_line:
                                continue
                            try:
                                json.loads(stripped_line)
                                total_lines += 1
                            except json.JSONDecodeError:
                                pass  # å¿½ç•¥éæ³•è¡Œ
                except Exception as e:
                    print(f"Error reading file {file_path}: {e}")
    return total_lines


def merge_all_jsonl_files(input_folders, output_folder, output_file_name="merged_output.jsonl"):
    """
    åˆå¹¶å¤šä¸ªè¾“å…¥æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰ .jsonl æ–‡ä»¶çš„å†…å®¹ï¼Œ
    è¾“å‡ºåˆ°è¾“å‡ºæ–‡ä»¶å¤¹ä¸‹çš„å•ä¸ªæ–‡ä»¶ä¸­ã€‚
    """
    output_file_path = os.path.join(output_folder, output_file_name)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_folder, exist_ok=True)

    new_lines_added = 0

    # æ¸…ç©ºæˆ–åˆ›å»ºè¾“å‡ºæ–‡ä»¶ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰
    with open(output_file_path, "w", encoding="utf-8") as outfile:
        for input_folder in input_folders:
            print(f"\nğŸ” Processing input folder: {input_folder}")
            for root, _, files in os.walk(input_folder):
                for file_name in files:
                    if file_name.endswith(".jsonl"):
                        input_file_path = os.path.join(root, file_name)
                        print(f"Processing: {input_file_path}")

                        try:
                            with open(input_file_path, "r", encoding="utf-8") as infile:
                                lines = infile.readlines()
                        except Exception as e:
                            print(f"Error reading file {input_file_path}: {e}")
                            continue

                        valid_lines = []
                        for line_number, line in enumerate(lines, start=1):
                            stripped_line = line.strip()
                            if not stripped_line:
                                continue
                            try:
                                data = json.loads(stripped_line)
                                valid_lines.append(data)
                            except json.JSONDecodeError:
                                continue  # è·³è¿‡éæ³•è¡Œ

                        # å†™å…¥åˆ°ç›®æ ‡æ–‡ä»¶
                        for item in valid_lines:
                            json.dump(item, outfile, ensure_ascii=False)
                            outfile.write("\n")

                        new_lines_added += len(valid_lines)

    print(f"\nâœ… åˆå¹¶å®Œæˆã€‚è¾“å‡ºæ–‡ä»¶ä¸ºï¼š{output_file_path}")
    print(f"ğŸ†• æ–°å¢è¡Œæ•°ï¼ˆæ¥è‡ªä¸¤ä¸ªè¾“å…¥æ–‡ä»¶å¤¹ï¼‰: {new_lines_added}")

    return new_lines_added


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    input_folder1 = r"D:\code\count\dataset\add_contentCopilot_sichuan_critiq"
    input_folder2 = r"D:\code\count\dataset\contentCopilot-sichuan-reject1p2"
    output_folder = r"D:\code\count\dataset\contentCopilot-sichuan-critiq_0710"

    # ç»Ÿè®¡è¾“å…¥æ–‡ä»¶å¤¹å„è‡ªçš„è¡Œæ•°
    count1 = count_jsonl_lines(input_folder1)
    count2 = count_jsonl_lines(input_folder2)

    print(f"\nğŸ“Š è¾“å…¥æ–‡ä»¶å¤¹1 æ€»è¡Œæ•°ï¼ˆæœ‰æ•ˆï¼‰: {count1}")
    print(f"ğŸ“Š è¾“å…¥æ–‡ä»¶å¤¹2 æ€»è¡Œæ•°ï¼ˆæœ‰æ•ˆï¼‰: {count2}")

    # åˆå¹¶åˆ°è¾“å‡ºæ–‡ä»¶å¤¹ä¸‹çš„å•ä¸ªæ–‡ä»¶
    merged_count = merge_all_jsonl_files([input_folder1, input_folder2], output_folder)

    # å¯é€‰ï¼šå†æ¬¡ç»Ÿè®¡è¾“å‡ºæ–‡ä»¶çš„æ€»è¡Œæ•°ä»¥ç¡®ä¿ä¸€è‡´æ€§
    output_file_path = os.path.join(output_folder, "merged_output.jsonl")
    with open(output_file_path, "r", encoding="utf-8") as f:
        final_line_count = sum(1 for line in f if line.strip())

    print(f"ğŸ“Š è¾“å‡ºæ–‡ä»¶æ€»è¡Œæ•°ï¼ˆæœ€ç»ˆç»“æœï¼‰: {final_line_count}")